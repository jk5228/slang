# A lexer generated by lexgen.py. This file is automatically generated.
# Do not edit.

import re, tok

ws = re.compile('\s+')
triples = [{0}]

# Return the number of newlines in the match object.
def countlines(match):
    return sum(group.count('\n') for group in match.groups())

# Generate tokens given a program string.
def lex(prog):
    linecount = 1

    while len(prog):

        match = None

        # Match token patterns
        for (label, typ, pattern) in triples:

            match = re.match(pattern, prog)

            if match:

                if typ == '<':pass
                elif match.groups('val'):
                    val = match.group('val')
                    end = val.count('\n')
                    yield tok.token(label, val, linecount, linecount+end)
                else:
                    val = prog[:match.end(0)]
                    end = val.count('\n')
                    yield tok.token(label, val, linecount, linecount+end)
                linecount += countlines(match)
                prog = prog[match.end(0):]
                break

        # No token patterns matched
        if not match:
            linefrag = ''
            try:
                linefrag = prog[:prog.index('\n')]
            except ValueError:
                linefrag = prog
            raise SyntaxError('line %d: unexpected sequence "%s".'
                              % (linecount, linefrag))